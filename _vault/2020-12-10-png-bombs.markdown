---
layout: post
type: post
title: "File bombs: a super cool DoS attack"
header-img: "img/explosion.jpg"
author: "AdriÃ "
date: 2020-12-10
catalog: true
mathjax: true
tags:
  - Denial of Service
  - Attack
---
A few months ago, after reading the API documentation of the startup I was working on, I discovered something quite interesting. Pillow (common library for image processing in Python) cannot process images with more than $2^{29}$ pixels i.e. a square image of $11585$ ($$sqrt(2^{29})\approx 2^{13.5} \approx 11585$) pixels for each side. I thought those cases were unfeasible and unrealistic, since an image of those dimensions would be huge (in terms of bytes). But then I came across this message in a [Github Issue](https://github.com/python-pillow/Pillow/issues/515): 

> "http://www.aerasec.de/security/advisories/decompression-bomb-vulnerability.html provides 2 PNG bomb demos, a 4KB 6000x6000 image that decompresses to 100MB in memory and a 44KB 19000x19000 image that decompresses to 1GB. JPEG is somewhat less efficient, but, for example, [NASA Visible Earth's Blue Marble has 21600x21600 tiles as small as 5MB (A2 tile, South Pacific) that decompress to 1.4GB](https://eoimages.gsfc.nasa.gov/images/imagerecords/73000/73884/world.topo.bathy.200411.3x21600x21600.A2.jpg)"

**Are we really talking about kilobytes? Not even a megabyte?! I wonder how many services are out there with this attack? (Disclaimer: I'm not encouraging you to try it, please don't).


### Creating a ZIP bomb
Only for merely educational purposes ðŸ‘€, let's try to make a zip *bomb*. Note that this zip bomb will not work in most of the cases, since most of the services that allow you to upload a zip file will check the size of the file before extracting it. But it's still a good exercise to understand how this attack works. Moreover, if the zip parser does not allow recursive decompression, it will be totally safe to decompress our bomb:


> "Compression bombs that use the zip format must cope with the fact that DEFLATE, the compression algorithm most commonly supported by zip parsers, cannot achieve a compression ratio greater than 1032. For this reason, zip bombs typically rely on recursive decompression, nesting zip files within zip files to get an extra factor of 1032 with each layer. But the trick only works on implementations that unzip recursively, and most do not. The best-known zip bomb, 42.zip, expands to a formidable 4.5 PB if all six of its layers are recursively unzipped, but a trifling 0.6 MB at the top layer. Zip quines, like those of Ellingsen and Cox, which contain a copy of themselves and thus expand infinitely if recursively unzipped, are likewise perfectly safe to unzip once." - [A better ZIP BOMB](https://www.bamsoftware.com/hacks/zipbomb/)


Compression relies on spotting repeating patterns, so if we can create a file with a lot of repeating patterns, we can compress it to a very small file. 

Let's start by creating a file with a size of 1MB full of zeros and compress it with `zip`:

```bash
-> % dd if=/dev/zero of=100MB.txt bs=1M count=100
-> % zip 100MB.zip 100MB.txt
-> % du -h 100MB.zip
100K	100MB.zip
```
If we take a look at the size of `1MB.zip`, we can see that it's 100KB. That is a compression rate of 1000. Pretty nice! 

Now to really make it a bomb, we need to make $n$ copies of that zip, pack those into a zip file, and repeat the process $m$ times. For example:

```bash 
-> % for i in {0..9}; do cp 100MB.zip $i.zip; done
-> % zip second_level.zip {0..9}.zip
-> % du -h second_level.zip
1000K	second_level.zip # fully uncompressed is 1GB

-> % for i in {0..9}; do cp second_level.zip 1$i.zip; done
-> % zip third_level.zip {10..19}.zip
-> % du -h third_level.zip
9.8M	third_level.zip
```

```third_level.zip``` weights only 9.8MB but truly contains 10GB. **We have a file of 9.8MB that decompresses to 10GB**. What if we started with a file of 1GB? What if we had more levels?

As you can imagine, this can explode pretty quickly (pun intended). 

